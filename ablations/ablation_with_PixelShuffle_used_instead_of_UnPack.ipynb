{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'switch':20000}\n",
    "opt.update({'lr':1e-4})\n",
    "\n",
    "opt['dir_root']='/home/mohit/Music/attention_low_light/'\n",
    "opt['exp_name'] = 'AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-vs-Pixelshuffle-relu_rectified'\n",
    "\n",
    "opt['gpu'] = \"0\"\n",
    "opt['epochs'] = 1000000\n",
    "opt['batch_size'] = 1\n",
    "opt['Shuffle'] = False\n",
    "opt['Pin_memory'] = True\n",
    "opt['workers'] = 1\n",
    "opt['patch'] = 512\n",
    "\n",
    "opt['fig_freq'] = 2000\n",
    "opt['save_freq'] = [2,20000,50000,80000,100000,150000,200000,250000,300000,350000,400000,450000,500000]\n",
    "opt['text_prnt_freq']=2000\n",
    "\n",
    "opt['fig_size'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torchvision.transforms.functional as Ft\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import skimage\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import normalized_root_mse as NRMSE\n",
    "from torch.autograd import Variable\n",
    "from math import exp\n",
    "import math\n",
    "import rawpy\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "##os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=opt['gpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num = random.randint(0, 20)\n",
    "num = (num//3)*3 \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data(Dataset):\n",
    "    \"\"\"Loads the Data.\"\"\"\n",
    "    \n",
    "    def __init__(self,opt):\n",
    "        self.train_files = glob.glob('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/short/1*_00_0.1s.ARW')\n",
    "\n",
    "        self.gt_files = []\n",
    "        for x in self.train_files:\n",
    "            self.gt_files =self.gt_files+ glob.glob('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/long/*'+x[-17:-12]+'*.ARW')\n",
    "        \n",
    "        self.to_tensor = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        \n",
    "        self.opt = opt\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.gt_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "       \n",
    "        raw = rawpy.imread(self.gt_files[idx])\n",
    "        \n",
    "        img_gt = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16).copy()\n",
    "        img_gtt=np.float32(img_gt/65535.0)\n",
    "\n",
    "        raw.close()\n",
    "        \n",
    "        raw = rawpy.imread(self.train_files[idx])\n",
    "        img = raw.raw_image_visible.astype(np.float32).copy()\n",
    "        raw.close()\n",
    "        \n",
    "        img_loww = (np.maximum(img - 512,0)/ (16383 - 512))\n",
    "        H,W = img_loww.shape\n",
    "        \n",
    "        ##############################################################################\n",
    "        \n",
    "        r_low=[]\n",
    "        g1_low=[]\n",
    "        g2_low=[]\n",
    "        b_low=[]\n",
    "\n",
    "        gt=[]\n",
    "        \n",
    "        for_amplifier=[]\n",
    "\n",
    "        for gener in range(1):\n",
    "            \n",
    "            if random.randint(0, 100)>50:\n",
    "                flip_flag = True\n",
    "            else:\n",
    "                flip_flag = False\n",
    "\n",
    "            if random.randint(0, 100)<20:\n",
    "                v_flag = True\n",
    "            else:\n",
    "                v_flag = False\n",
    "\n",
    "        #     print(H)\n",
    "\n",
    "            i = random.randint(0, (H-self.opt['patch']-2)//2)*2\n",
    "            j = random.randint(0,(W-self.opt['patch']-2)//2)*2\n",
    "\n",
    "            img_low = img_loww#[i:i+self.opt['patch'],j:j+self.opt['patch']]\n",
    "            img_gt = img_gtt#[i:i+self.opt['patch'],j:j+self.opt['patch'],:]\n",
    "            \n",
    "            if False:\n",
    "                img_gt = np.flip(img_gt, 0).copy()\n",
    "                img_low = np.flip(img_low, 0).copy()\n",
    "\n",
    "            if False:\n",
    "                img_gt = np.flip(img_gt, 1).copy()\n",
    "                img_low = np.flip(img_low, 1).copy()\n",
    "\n",
    "            img_low_r = img_low[0:H:2,0:W:2]\n",
    "            img_low_g1 = img_low[0:H:2,1:W:2]\n",
    "            img_low_g2 = img_low[1:H:2,0:W:2]\n",
    "            img_low_b = img_low[1:H:2,1:W:2]\n",
    "            \n",
    "            for_amplifier.append(torch.from_numpy(np.transpose(np.dstack((img_low_r,img_low_g1,img_low_g2,img_low_b)), [2, 0, 1])).float())\n",
    "            \n",
    "\n",
    "            img_gt_avg = np.zeros((H//8,W//8,int(64*3))).astype(np.float32)\n",
    "\n",
    "#             r_avg = np.zeros((opt['patch']//16,opt['patch']//16,64)).astype(np.float32)\n",
    "#             g1_avg = np.zeros((opt['patch']//16,opt['patch']//16,64)).astype(np.float32)\n",
    "#             g2_avg = np.zeros((opt['patch']//16,opt['patch']//16,64)).astype(np.float32)\n",
    "#             b_avg = np.zeros((opt['patch']//16,opt['patch']//16,64)).astype(np.float32)\n",
    "\n",
    "            count_gt=0\n",
    "            count_raw = 0\n",
    "            for ii in range(8):\n",
    "                for jj in range(8):\n",
    "\n",
    "                    img_gt_avg[:,:,count_gt:count_gt+3] = img_gt[ii:H:8,jj:W:8,:]\n",
    "                    count_gt=count_gt+3\n",
    "        #             print(count_gt)\n",
    "\n",
    "#                     r_avg[:,:,count_raw] = img_low_r[ii:opt['patch']//2:8,jj:opt['patch']//2:8]\n",
    "#                     g1_avg[:,:,count_raw] = img_low_g1[ii:opt['patch']//2:8,jj:opt['patch']//2:8]\n",
    "#                     g2_avg[:,:,count_raw] = img_low_g2[ii:opt['patch']//2:8,jj:opt['patch']//2:8]\n",
    "#                     b_avg[:,:,count_raw] = img_low_b[ii:opt['patch']//2:8,jj:opt['patch']//2:8]\n",
    "#                     count_raw=count_raw+1\n",
    "#         #             print('{},{},{}'.format(count_raw,ii,jj))\n",
    "\n",
    "            \n",
    "            gt.append(torch.from_numpy((np.transpose(img_gt_avg, [2, 0, 1]))).float())\n",
    "            r_low.append(torch.from_numpy((np.transpose(img_low_r, [0, 1]))).float().unsqueeze(0))\n",
    "            g1_low.append(torch.from_numpy((np.transpose(img_low_g1, [0, 1]))).float().unsqueeze(0))\n",
    "            g2_low.append(torch.from_numpy((np.transpose(img_low_g2, [0, 1]))).float().unsqueeze(0))\n",
    "            b_low.append(torch.from_numpy((np.transpose(img_low_b, [0, 1]))).float().unsqueeze(0))\n",
    "            \n",
    "        \n",
    "        return gt, r_low, g1_low, g2_low, b_low, for_amplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_train = get_data(opt)\n",
    "dataloader_train = DataLoader(obj_train, batch_size=opt['batch_size'], shuffle=opt['Shuffle'], num_workers=opt['workers'], pin_memory=opt['Pin_memory'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_c):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_c,in_c, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_c,in_c, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = out + identity\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class make_dense(nn.Module):\n",
    "    \n",
    "    def __init__(self, nChannels=64, growthRate=32, kernel_size=3):\n",
    "        super(make_dense, self).__init__()\n",
    "        self.conv = nn.Conv2d(nChannels, growthRate, kernel_size=kernel_size, padding=(kernel_size-1)//2, bias=False)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv(x))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "    \n",
    "# Residual dense block (RDB) architecture\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, nChannels=64, nDenselayer=6, growthRate=32):\n",
    "        super(RDB, self).__init__()\n",
    "        nChannels_ = nChannels\n",
    "        modules = []\n",
    "        for i in range(nDenselayer):    \n",
    "            modules.append(make_dense(nChannels_, growthRate))\n",
    "            nChannels_ += growthRate \n",
    "        self.dense_layers = nn.Sequential(*modules)    \n",
    "        self.conv_1x1 = nn.Conv2d(nChannels_, nChannels, kernel_size=1, padding=0, bias=False)\n",
    "    def forward(self, x):\n",
    "        out = self.dense_layers(x)\n",
    "        out = self.conv_1x1(out)\n",
    "        out = out + x\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "class amplifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,channels):\n",
    "        super(amplifier, self).__init__()\n",
    "        \n",
    "        self.relu = nn.Threshold(threshold=0, value=0.0001, inplace=True)\n",
    "        \n",
    "        # size:256\n",
    "        self.conv_pre = nn.Sequential(\n",
    "            nn.Conv2d(channels,16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            # size:128\n",
    "#             nn.Conv2d(16,32, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "#             # size:64\n",
    "#             nn.Conv2d(32,64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "#             # size:32\n",
    "        )\n",
    "        \n",
    "        self.conv_post = nn.Sequential(\n",
    "            nn.Conv2d(16,128, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Conv2d(128,1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         print(x.size())\n",
    "#         identity = x\n",
    "        \n",
    "        x = self.conv_pre(x)\n",
    "        \n",
    "        # (global average pooling)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        \n",
    "        # interact\n",
    "        gamma = self.relu(self.conv_post(x))\n",
    "#         print(gamma)\n",
    "        \n",
    "#         x = identity*gamma\n",
    "#         print(x.size())\n",
    "        return gamma\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.amplifier = amplifier(4)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.RDBr = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBg1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBg2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBb = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        self.before_identity = nn.Conv2d(in_channels=int(4*64), out_channels=64, kernel_size=1, stride=1, bias=False)\n",
    "        self.after_rdb = nn.Conv2d(in_channels=int(3*64), out_channels=64, kernel_size=1, stride=1, bias=False)\n",
    "        \n",
    "        self.RDB1 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        self.RDB2 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        self.RDB3 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.PixelShuffle(2),\n",
    "            RDB(nChannels=16, nDenselayer=6, growthRate=32),\n",
    "            nn.Conv2d(in_channels=16, out_channels=int(64*3), kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            self.relu,\n",
    "            nn.PixelShuffle(8)\n",
    "            \n",
    "        ) \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,r_low,g1_low,g2_low,b_low,for_amplifier):\n",
    "        \n",
    "#         gamma = self.amplifier(torch.cat((r_low,g1_low,g2_low,b_low),dim=1))\n",
    "\n",
    "        b, c, h, w = r_low.size()\n",
    "        \n",
    "        out_channel = c*(8**2)\n",
    "        out_h = h//8\n",
    "        out_w = w//8\n",
    "        low_view = r_low.contiguous().view(b, c, out_h, 8, out_w, 8)\n",
    "        r_low = low_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\n",
    "        \n",
    "        b, c, h, w = g1_low.size()\n",
    "        \n",
    "        out_channel = c*(8**2)\n",
    "        out_h = h//8\n",
    "        out_w = w//8\n",
    "        low_view = g1_low.contiguous().view(b, c, out_h, 8, out_w, 8)\n",
    "        g1_low = low_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\n",
    "        \n",
    "        b, c, h, w = g2_low.size()\n",
    "        \n",
    "        out_channel = c*(8**2)\n",
    "        out_h = h//8\n",
    "        out_w = w//8\n",
    "        low_view = g2_low.contiguous().view(b, c, out_h, 8, out_w, 8)\n",
    "        g2_low = low_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\n",
    "        \n",
    "        b, c, h, w = b_low.size()\n",
    "        \n",
    "        out_channel = c*(8**2)\n",
    "        out_h = h//8\n",
    "        out_w = w//8\n",
    "        low_view = b_low.contiguous().view(b, c, out_h, 8, out_w, 8)\n",
    "        b_low = low_view.permute(0,1,3,5,2,4).contiguous().view(b,out_channel, out_h, out_w)\n",
    "\n",
    "        gamma = self.amplifier(for_amplifier)\n",
    "        \n",
    "        r_low = self.relu(self.RDBr(r_low*gamma))\n",
    "        g1_low = self.relu(self.RDBg1(g1_low*gamma))\n",
    "        g2_low = self.relu(self.RDBg2(g2_low*gamma))\n",
    "        b_low = self.relu(self.RDBb(b_low*gamma))\n",
    "        \n",
    "        alll=self.before_identity(torch.cat((r_low,g1_low,g2_low,b_low),dim=1))\n",
    "        \n",
    "        identity = alll\n",
    "        \n",
    "        rdb1 = self.RDB1(alll)\n",
    "        rdb2 = self.RDB2(rdb1)\n",
    "        rdb3 = self.RDB3(rdb2)\n",
    "        \n",
    "        alll = self.after_rdb(torch.cat((rdb1,rdb2,rdb3),dim=1))+identity\n",
    "        \n",
    "        alll = self.final(alll)\n",
    "        \n",
    "        \n",
    "        return alll,gamma\n",
    "    \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class common_functions():\n",
    "    \n",
    "    def __init__(self, opt):\n",
    "        \n",
    "        self.opt = opt\n",
    "        self.count = 0\n",
    "                        \n",
    "        self.device = torch.device(\"cuda\")\n",
    "        \n",
    "\n",
    "        \n",
    "        model = Net()#.apply(self.weights_init_kaiming)\n",
    "        print('Trainable parameters : {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "        \n",
    "        self.model = model.to(self.device)\n",
    "        print(self.model)\n",
    "        print(next(self.model.parameters()).is_cuda)  \n",
    "        \n",
    "        checkpoint = torch.load(self.opt['dir_root']+'weights/'+self.opt['exp_name']+'_{}'.format(400000))\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "  \n",
    "    \n",
    "    def optimize_parameters(self,r_low,g1_low,g2_low,b_low,gt,for_amplifier):\n",
    "        \n",
    "        \n",
    "        \n",
    "#         num = random.randint(0, 191)\n",
    "#         self.num = (num//3)*3 \n",
    "        \n",
    "        r_low=r_low.to(self.device)\n",
    "        g1_low=g1_low.to(self.device)\n",
    "        g2_low=g2_low.to(self.device)\n",
    "        b_low=b_low.to(self.device)\n",
    "        gt=gt.to(self.device)\n",
    "        for_amplifier=for_amplifier.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            beg = time.time()\n",
    "            plot_out_pred, gamma = self.model(r_low,g1_low,g2_low,b_low,for_amplifier)\n",
    "            end = time.time()\n",
    "        \n",
    "        begg = time.time()\n",
    "        \n",
    "        plot_out_GT = torch.zeros(1,3,2848,4256, dtype=torch.float).to(self.device)\n",
    "        counttt=0\n",
    "        for ii in range(8):\n",
    "                for jj in range(8):\n",
    "\n",
    "                    plot_out_GT[:,:,ii:2848:8,jj:4256:8] = gt[:,counttt:counttt+3,:,:]\n",
    "                    \n",
    "                    counttt=counttt+3\n",
    "        \n",
    "        endd = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "         \n",
    "        self.count +=1\n",
    "            \n",
    "            \n",
    "        if True:\n",
    "            \n",
    "            plot_out_pred = (np.clip(plot_out_pred[0].detach().cpu().numpy().transpose(1,2,0),0,1)*255).astype(np.uint8)\n",
    "            plot_out_GT = (np.clip(plot_out_GT[0].detach().cpu().numpy().transpose(1,2,0),0,1)*255).astype(np.uint8)\n",
    "#             print(gt.shape)\n",
    "#             print(np.dtype(pred_output))\n",
    "            \n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"PSNR: {0:.3f}, SSIM: {1:.3f}, RMSE:{2:.3f}, time:{3:.5f}, time:{4:.5f}\".format(PSNR(plot_out_GT,plot_out_pred), SSIM(plot_out_GT,plot_out_pred,multichannel=True),NRMSE(plot_out_GT,plot_out_pred), end-beg,endd-begg))\n",
    "            \n",
    "            # Save images\n",
    "            imageio.imwrite('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/results/AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-VS-Pixelshuffle-Testing-relu_shift/{}_IMG_PRED.png'.format(self.count),plot_out_pred)\n",
    "            imageio.imwrite('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/results/AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-VS-Pixelshuffle-Testing-relu_shift/{}_IMG_GT.png'.format(self.count),plot_out_GT)\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters : 1171985\n",
      "Net(\n",
      "  (amplifier): amplifier(\n",
      "    (relu): Threshold(threshold=0, value=0.0001, inplace=True)\n",
      "    (conv_pre): Sequential(\n",
      "      (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv_post): Sequential(\n",
      "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (RDBr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBg1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBg2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBb): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (before_identity): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (after_rdb): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (RDB1): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (RDB2): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (RDB3): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (final): Sequential(\n",
      "    (0): PixelShuffle(upscale_factor=2)\n",
      "    (1): RDB(\n",
      "      (dense_layers): Sequential(\n",
      "        (0): make_dense(\n",
      "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): make_dense(\n",
      "          (conv): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): make_dense(\n",
      "          (conv): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): make_dense(\n",
      "          (conv): Conv2d(112, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): make_dense(\n",
      "          (conv): Conv2d(144, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): make_dense(\n",
      "          (conv): Conv2d(176, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv_1x1): Conv2d(208, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Conv2d(16, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): PixelShuffle(upscale_factor=8)\n",
      "  )\n",
      ")\n",
      "True\n",
      "PSNR: 21.494, SSIM: 0.864, RMSE:0.210, time:0.16528, time:0.25619\n",
      "PSNR: 20.928, SSIM: 0.650, RMSE:0.247, time:0.00440, time:0.25712\n",
      "PSNR: 17.560, SSIM: 0.558, RMSE:0.419, time:0.00433, time:0.25687\n",
      "PSNR: 18.499, SSIM: 0.639, RMSE:0.326, time:0.00469, time:0.25547\n",
      "PSNR: 26.453, SSIM: 0.934, RMSE:0.173, time:0.00470, time:0.24909\n",
      "PSNR: 23.506, SSIM: 0.649, RMSE:0.326, time:0.00481, time:0.26272\n",
      "PSNR: 20.567, SSIM: 0.570, RMSE:0.244, time:0.00437, time:0.25689\n",
      "PSNR: 23.786, SSIM: 0.757, RMSE:0.404, time:0.00428, time:0.25403\n",
      "PSNR: 24.635, SSIM: 0.743, RMSE:0.364, time:0.00435, time:0.26498\n",
      "PSNR: 20.001, SSIM: 0.487, RMSE:0.456, time:0.00681, time:0.29775\n",
      "PSNR: 25.907, SSIM: 0.789, RMSE:0.181, time:0.00443, time:0.25660\n",
      "PSNR: 24.768, SSIM: 0.520, RMSE:0.308, time:0.00452, time:0.26396\n",
      "PSNR: 22.640, SSIM: 0.817, RMSE:0.218, time:0.00473, time:0.24939\n",
      "PSNR: 25.508, SSIM: 0.847, RMSE:0.251, time:0.00440, time:0.24451\n",
      "PSNR: 23.872, SSIM: 0.619, RMSE:0.453, time:0.00459, time:0.25420\n",
      "PSNR: 17.272, SSIM: 0.652, RMSE:1.221, time:0.00441, time:0.25770\n",
      "PSNR: 25.022, SSIM: 0.614, RMSE:0.286, time:0.00432, time:0.25324\n",
      "PSNR: 20.921, SSIM: 0.840, RMSE:0.575, time:0.00476, time:0.25374\n",
      "PSNR: 21.421, SSIM: 0.667, RMSE:0.242, time:0.00441, time:0.25158\n",
      "PSNR: 20.058, SSIM: 0.813, RMSE:0.226, time:0.00440, time:0.25491\n",
      "PSNR: 22.912, SSIM: 0.681, RMSE:0.291, time:0.00447, time:0.25052\n",
      "PSNR: 21.055, SSIM: 0.661, RMSE:0.335, time:0.00437, time:0.25014\n",
      "PSNR: 20.357, SSIM: 0.626, RMSE:0.447, time:0.00439, time:0.25373\n",
      "PSNR: 20.275, SSIM: 0.613, RMSE:0.419, time:0.00442, time:0.24529\n",
      "PSNR: 25.919, SSIM: 0.593, RMSE:0.179, time:0.00429, time:0.24946\n",
      "PSNR: 21.748, SSIM: 0.601, RMSE:0.374, time:0.00426, time:0.24748\n",
      "PSNR: 21.952, SSIM: 0.537, RMSE:0.483, time:0.00432, time:0.25286\n",
      "PSNR: 19.638, SSIM: 0.665, RMSE:0.253, time:0.00435, time:0.25693\n",
      "PSNR: 25.367, SSIM: 0.761, RMSE:0.262, time:0.00544, time:0.25851\n",
      "PSNR: 22.849, SSIM: 0.579, RMSE:0.220, time:0.00430, time:0.25607\n",
      "PSNR: 22.958, SSIM: 0.928, RMSE:0.154, time:0.00429, time:0.25464\n",
      "PSNR: 26.143, SSIM: 0.694, RMSE:0.298, time:0.00447, time:0.25389\n",
      "PSNR: 14.743, SSIM: 0.624, RMSE:0.588, time:0.00427, time:0.26197\n",
      "PSNR: 17.326, SSIM: 0.615, RMSE:0.476, time:0.00448, time:0.24639\n",
      "PSNR: 19.013, SSIM: 0.589, RMSE:0.408, time:0.00433, time:0.25026\n",
      "PSNR: 17.999, SSIM: 0.775, RMSE:0.369, time:0.00437, time:0.23787\n",
      "PSNR: 26.243, SSIM: 0.678, RMSE:0.283, time:0.00775, time:0.24542\n",
      "PSNR: 22.334, SSIM: 0.684, RMSE:0.364, time:0.00447, time:0.25716\n",
      "PSNR: 18.860, SSIM: 0.706, RMSE:0.416, time:0.00431, time:0.24249\n",
      "PSNR: 18.336, SSIM: 0.351, RMSE:0.358, time:0.00451, time:0.25095\n",
      "PSNR: 16.996, SSIM: 0.519, RMSE:0.685, time:0.00439, time:0.25098\n",
      "PSNR: 28.325, SSIM: 0.527, RMSE:0.190, time:0.00444, time:0.23907\n",
      "PSNR: 19.426, SSIM: 0.735, RMSE:0.357, time:0.00684, time:0.25522\n",
      "PSNR: 20.118, SSIM: 0.645, RMSE:0.425, time:0.00431, time:0.25323\n",
      "PSNR: 27.800, SSIM: 0.681, RMSE:0.319, time:0.00453, time:0.25536\n",
      "PSNR: 19.708, SSIM: 0.771, RMSE:0.227, time:0.00438, time:0.25374\n",
      "PSNR: 24.714, SSIM: 0.784, RMSE:0.415, time:0.00431, time:0.25401\n",
      "PSNR: 14.860, SSIM: 0.715, RMSE:0.367, time:0.00441, time:0.25061\n",
      "PSNR: 29.336, SSIM: 0.929, RMSE:0.145, time:0.00424, time:0.25454\n",
      "PSNR: 24.655, SSIM: 0.720, RMSE:0.297, time:0.00422, time:0.25224\n"
     ]
    }
   ],
   "source": [
    "gan_model = common_functions(opt)\n",
    "\n",
    "for iteration, img in enumerate(dataloader_train):\n",
    "    gt = img[0]\n",
    "    r_low = img[1]\n",
    "    g1_low = img[2]\n",
    "    g2_low = img[3]\n",
    "    b_low = img[4]\n",
    "    for_amplifier = img[5]\n",
    "\n",
    "    for faster in range(1):\n",
    "\n",
    "        gan_model.optimize_parameters(r_low[faster],g1_low[faster],g2_low[faster],b_low[faster],gt[faster],for_amplifier[faster])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
