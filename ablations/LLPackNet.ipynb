{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {'switch':20000}\n",
    "opt.update({'lr':1e-4})\n",
    "\n",
    "opt['dir_root']='/home/mohit/Music/attention_low_light/'\n",
    "opt['exp_name'] = 'AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-RELU_remove' # the weights can be found in the 'ablations/weights' folder\n",
    "\n",
    "opt['gpu'] = \"1\"\n",
    "opt['epochs'] = 1000000\n",
    "opt['batch_size'] = 1\n",
    "opt['Shuffle'] = False\n",
    "opt['Pin_memory'] = True\n",
    "opt['workers'] = 1\n",
    "opt['patch'] = 512\n",
    "\n",
    "opt['fig_freq'] = 2000\n",
    "opt['save_freq'] = [2,200000,400000,450000,500000]\n",
    "opt['text_prnt_freq']=2000\n",
    "\n",
    "opt['fig_size'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import torchvision.transforms.functional as Ft\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import skimage\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as PSNR\n",
    "from skimage.metrics import structural_similarity as SSIM\n",
    "from skimage.metrics import normalized_root_mse as NRMSE\n",
    "from torch.autograd import Variable\n",
    "from math import exp\n",
    "import math\n",
    "import rawpy\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "##os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=opt['gpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num = random.randint(0, 20)\n",
    "num = (num//3)*3 \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_data(Dataset):\n",
    "    \"\"\"Loads the Data.\"\"\"\n",
    "    \n",
    "    def __init__(self,opt):\n",
    "        self.train_files = glob.glob('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/short/1*_00_0.1s.ARW')\n",
    "#         self.train_files = self.train_files + glob.glob('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/short/2*_00_0.1s.ARW')\n",
    "\n",
    "\n",
    "        self.gt_files = []\n",
    "        for x in self.train_files:\n",
    "            self.gt_files =self.gt_files+ glob.glob('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/long/*'+x[-17:-12]+'*.ARW')\n",
    "        \n",
    "        self.to_tensor = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        \n",
    "        self.opt = opt\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.gt_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "       \n",
    "        raw = rawpy.imread(self.gt_files[idx])\n",
    "        \n",
    "        img_gt = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16).copy()\n",
    "        img_gtt=np.float32(img_gt/65535.0)\n",
    "\n",
    "        raw.close()\n",
    "        \n",
    "        raw = rawpy.imread(self.train_files[idx])\n",
    "        img = raw.raw_image_visible.astype(np.float32).copy()\n",
    "        raw.close()\n",
    "        \n",
    "        img_loww = (np.maximum(img - 512,0)/ (16383 - 512))\n",
    "        H,W = img_loww.shape\n",
    "        \n",
    "        ##############################################################################\n",
    "        \n",
    "        r_low=[]\n",
    "        g1_low=[]\n",
    "        g2_low=[]\n",
    "        b_low=[]\n",
    "\n",
    "        gt=[]\n",
    "        \n",
    "        for_amplifier=[]\n",
    "\n",
    "        for gener in range(1):\n",
    "            \n",
    "            if random.randint(0, 100)>50:\n",
    "                flip_flag = False\n",
    "            else:\n",
    "                flip_flag = False\n",
    "\n",
    "            if random.randint(0, 100)<20:\n",
    "                v_flag = False\n",
    "            else:\n",
    "                v_flag = False\n",
    "\n",
    "        #     print(H)\n",
    "        \n",
    "#             H,W = img.shape\n",
    "\n",
    "            i = 0#random.randint(0, (H-self.opt['patch']-2)//2)*2\n",
    "            j = 0#random.randint(0,(W-self.opt['patch']-2)//2)*2\n",
    "\n",
    "            img_low = img_loww[i:i+H,j:j+W]\n",
    "            img_gt = img_gtt[i:i+H,j:j+W,:]\n",
    "            \n",
    "            if flip_flag:\n",
    "                img_gt = np.flip(img_gt, 0).copy()\n",
    "                img_low = np.flip(img_low, 0).copy()\n",
    "\n",
    "            if v_flag:\n",
    "                img_gt = np.flip(img_gt, 1).copy()\n",
    "                img_low = np.flip(img_low, 1).copy()\n",
    "\n",
    "            img_low_r = img_low[0:H:2,0:W:2]\n",
    "            img_low_g1 = img_low[0:H:2,1:W:2]\n",
    "            img_low_g2 = img_low[1:H:2,0:W:2]\n",
    "            img_low_b = img_low[1:H:2,1:W:2]\n",
    "            \n",
    "            for_amplifier.append(torch.from_numpy(np.transpose(np.dstack((img_low_r,img_low_g1,img_low_g2,img_low_b)), [2, 0, 1])).float())\n",
    "            \n",
    "\n",
    "            img_gt_avg = np.zeros((H//8,W//8,int(64*3))).astype(np.float32)\n",
    "\n",
    "            r_avg = np.zeros((H//16,W//16,64)).astype(np.float32)\n",
    "            g1_avg = np.zeros((H//16,W//16,64)).astype(np.float32)\n",
    "            g2_avg = np.zeros((H//16,W//16,64)).astype(np.float32)\n",
    "            b_avg = np.zeros((H//16,W//16,64)).astype(np.float32)\n",
    "\n",
    "            count_gt=0\n",
    "            count_raw = 0\n",
    "            for ii in range(8):\n",
    "                for jj in range(8):\n",
    "\n",
    "                    img_gt_avg[:,:,count_gt:count_gt+3] = img_gt[ii:H:8,jj:W:8,:]\n",
    "                    count_gt=count_gt+3\n",
    "        #             print(count_gt)\n",
    "\n",
    "                    r_avg[:,:,count_raw] = img_low_r[ii:H//2:8,jj:W//2:8]\n",
    "                    g1_avg[:,:,count_raw] = img_low_g1[ii:H//2:8,jj:W//2:8]\n",
    "                    g2_avg[:,:,count_raw] = img_low_g2[ii:H//2:8,jj:W//2:8]\n",
    "                    b_avg[:,:,count_raw] = img_low_b[ii:H//2:8,jj:W//2:8]\n",
    "                    count_raw=count_raw+1\n",
    "        #             print('{},{},{}'.format(count_raw,ii,jj))\n",
    "\n",
    "            \n",
    "            gt.append(torch.from_numpy((np.transpose(img_gt_avg, [2, 0, 1]))).float())\n",
    "            r_low.append(torch.from_numpy((np.transpose(r_avg, [2, 0, 1]))).float())\n",
    "            g1_low.append(torch.from_numpy((np.transpose(g1_avg, [2, 0, 1]))).float())\n",
    "            g2_low.append(torch.from_numpy((np.transpose(g2_avg, [2, 0, 1]))).float())\n",
    "            b_low.append(torch.from_numpy((np.transpose(b_avg, [2, 0, 1]))).float())\n",
    "            \n",
    "        \n",
    "        return gt, r_low, g1_low, g2_low, b_low, for_amplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_train = get_data(opt)\n",
    "dataloader_train = DataLoader(obj_train, batch_size=opt['batch_size'], shuffle=opt['Shuffle'], num_workers=opt['workers'], pin_memory=opt['Pin_memory'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_c):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_c,in_c, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(in_c,in_c, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = out + identity\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class make_dense(nn.Module):\n",
    "    \n",
    "    def __init__(self, nChannels=64, growthRate=32, kernel_size=3):\n",
    "        super(make_dense, self).__init__()\n",
    "        self.conv = nn.Conv2d(nChannels, growthRate, kernel_size=kernel_size, padding=(kernel_size-1)//2, bias=False)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv(x))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "    \n",
    "# Residual dense block (RDB) architecture\n",
    "class RDB(nn.Module):\n",
    "    def __init__(self, nChannels=64, nDenselayer=6, growthRate=32):\n",
    "        super(RDB, self).__init__()\n",
    "        nChannels_ = nChannels\n",
    "        modules = []\n",
    "        for i in range(nDenselayer):    \n",
    "            modules.append(make_dense(nChannels_, growthRate))\n",
    "            nChannels_ += growthRate \n",
    "        self.dense_layers = nn.Sequential(*modules)    \n",
    "        self.conv_1x1 = nn.Conv2d(nChannels_, nChannels, kernel_size=1, padding=0, bias=False)\n",
    "    def forward(self, x):\n",
    "        out = self.dense_layers(x)\n",
    "        out = self.conv_1x1(out)\n",
    "        out = out + x\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "class amplifier(nn.Module):\n",
    "# We take this opportunity to show that our Network is insensitive to amplifier choice. For example in 'train.py' we use the one kind of amplifier. Here however we use another variant of that and find no change in the performance.     \n",
    "    def __init__(self,channels):\n",
    "        super(amplifier, self).__init__()\n",
    "        \n",
    "        self.relu = nn.Threshold(threshold=0, value=0.0001, inplace=True)\n",
    "        \n",
    "        # size:256\n",
    "        self.conv_pre = nn.Sequential(\n",
    "            nn.Conv2d(channels,16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            # size:128\n",
    "#             nn.Conv2d(16,32, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "#             # size:64\n",
    "#             nn.Conv2d(32,64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "#             # size:32\n",
    "        )\n",
    "        \n",
    "        self.conv_post = nn.Sequential(\n",
    "            nn.Conv2d(16,128, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Conv2d(128,1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "#         print(x.size())\n",
    "#         identity = x\n",
    "        \n",
    "        x = self.conv_pre(x)\n",
    "        \n",
    "        # (global average pooling)\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        \n",
    "        # interact\n",
    "        gamma = self.relu(self.conv_post(x))\n",
    "#         print(gamma)\n",
    "        \n",
    "#         x = identity*gamma\n",
    "#         print(x.size())\n",
    "        return gamma\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.amplifier = amplifier(4)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.RDBr = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBg1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBg2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        self.RDBb = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        \n",
    "        self.before_identity = nn.Conv2d(in_channels=int(4*64), out_channels=64, kernel_size=1, stride=1, bias=False)\n",
    "        self.after_rdb = nn.Conv2d(in_channels=int(3*64), out_channels=64, kernel_size=1, stride=1, bias=False)\n",
    "        \n",
    "        self.RDB1 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        self.RDB2 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        self.RDB3 = RDB(nChannels=64, nDenselayer=6, growthRate=32)\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.PixelShuffle(2),\n",
    "            RDB(nChannels=16, nDenselayer=6, growthRate=32),\n",
    "            nn.Conv2d(in_channels=16, out_channels=int(64*3), kernel_size=3, stride=1, padding=1, bias=True),\n",
    "#             self.relu\n",
    "        ) \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,r_low,g1_low,g2_low,b_low,for_amplifier):\n",
    "        \n",
    "#         gamma = self.amplifier(torch.cat((r_low,g1_low,g2_low,b_low),dim=1))\n",
    "\n",
    "        gamma = self.amplifier(for_amplifier)\n",
    "        \n",
    "        r_low = self.relu(self.RDBr(r_low*gamma))\n",
    "        g1_low = self.relu(self.RDBg1(g1_low*gamma))\n",
    "        g2_low = self.relu(self.RDBg2(g2_low*gamma))\n",
    "        b_low = self.relu(self.RDBb(b_low*gamma))\n",
    "        \n",
    "        alll=self.before_identity(torch.cat((r_low,g1_low,g2_low,b_low),dim=1))\n",
    "        \n",
    "        identity = alll\n",
    "        \n",
    "        rdb1 = self.RDB1(alll)\n",
    "        rdb2 = self.RDB2(rdb1)\n",
    "        rdb3 = self.RDB3(rdb2)\n",
    "        \n",
    "        alll = self.after_rdb(torch.cat((rdb1,rdb2,rdb3),dim=1))+identity\n",
    "        \n",
    "        alll = self.final(alll)\n",
    "        \n",
    "        \n",
    "        return alll,gamma\n",
    "    \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class common_functions():\n",
    "    \n",
    "    def __init__(self, opt):\n",
    "        \n",
    "        self.opt = opt\n",
    "        self.count = 0\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "                        \n",
    "        self.device = torch.device(\"cuda\")\n",
    "        \n",
    "\n",
    "        model = Net()#.apply(self.weights_init_kaiming)\n",
    "        print('Trainable parameters : {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "        \n",
    "        self.model = model.to(self.device)\n",
    "        print(self.model)\n",
    "        print(next(self.model.parameters()).is_cuda)  \n",
    "        \n",
    "        checkpoint = torch.load(self.opt['dir_root']+'weights/'+self.opt['exp_name']+'_{}'.format(400000))\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "  \n",
    "    \n",
    "    def optimize_parameters(self,r_low,g1_low,g2_low,b_low,gt,for_amplifier):\n",
    "        \n",
    "        \n",
    "        \n",
    "#         num = random.randint(0, 191)\n",
    "#         self.num = (num//3)*3 \n",
    "        \n",
    "        r_low=r_low.to(self.device)\n",
    "        g1_low=g1_low.to(self.device)\n",
    "        g2_low=g2_low.to(self.device)\n",
    "        b_low=b_low.to(self.device)\n",
    "        gt=gt.to(self.device)\n",
    "        for_amplifier=for_amplifier.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            beg = time.time()\n",
    "            pred_output, gamma = self.model(r_low,g1_low,g2_low,b_low,for_amplifier)\n",
    "            end = time.time()\n",
    "        \n",
    "        begg = time.time()\n",
    "        \n",
    "        plot_out_GT = torch.zeros(1,3,2848,4256, dtype=torch.float).to(self.device)\n",
    "        plot_out_pred = torch.zeros(1,3,2848,4256, dtype=torch.float).to(self.device)\n",
    "        counttt=0\n",
    "        for ii in range(8):\n",
    "                for jj in range(8):\n",
    "\n",
    "                    plot_out_GT[:,:,ii:2848:8,jj:4256:8] = gt[:,counttt:counttt+3,:,:]\n",
    "                    plot_out_pred[:,:,ii:2848:8,jj:4256:8] = pred_output[:,counttt:counttt+3,:,:]\n",
    "                    \n",
    "                    counttt=counttt+3\n",
    "        \n",
    "        endd = time.time()\n",
    "\n",
    "        \n",
    "        self.count +=1\n",
    "            \n",
    "            \n",
    "        if True:\n",
    "            \n",
    "            plot_out_pred = (np.clip(plot_out_pred[0].detach().cpu().numpy().transpose(1,2,0),0,1)*255).astype(np.uint8)\n",
    "            plot_out_GT = (np.clip(plot_out_GT[0].detach().cpu().numpy().transpose(1,2,0),0,1)*255).astype(np.uint8)\n",
    "#             print(gt.shape)\n",
    "#             print(np.dtype(pred_output))\n",
    "            \n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"PSNR: {0:.3f}, SSIM: {1:.3f}, RMSE:{2:.3f}, time:{3:.5f}, time:{4:.5f}\".format(PSNR(plot_out_GT,plot_out_pred), SSIM(plot_out_GT,plot_out_pred,multichannel=True),NRMSE(plot_out_GT,plot_out_pred), end-beg,endd-begg))\n",
    "            \n",
    "            # Save images\n",
    "            imageio.imwrite('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/results/AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-RELU_remove-Testing/{}_IMG_PRED.png'.format(self.count),plot_out_pred)\n",
    "            imageio.imwrite('/media/mohit/data/mohit/chen_dark_cvpr_18_dataset/Sony/results/AVG-on-1-10-sec-raw2rgb-patch512-fullVGG-RELU_remove-Testing/{}_IMG_GT.png'.format(self.count),plot_out_GT)\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters : 1171985\n",
      "Net(\n",
      "  (amplifier): amplifier(\n",
      "    (relu): Threshold(threshold=0, value=0.0001, inplace=True)\n",
      "    (conv_pre): Sequential(\n",
      "      (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (conv_post): Sequential(\n",
      "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (RDBr): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBg1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBg2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (RDBb): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (before_identity): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (after_rdb): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (RDB1): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (RDB2): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (RDB3): RDB(\n",
      "    (dense_layers): Sequential(\n",
      "      (0): make_dense(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): make_dense(\n",
      "        (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): make_dense(\n",
      "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (3): make_dense(\n",
      "        (conv): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): make_dense(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): make_dense(\n",
      "        (conv): Conv2d(224, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (final): Sequential(\n",
      "    (0): PixelShuffle(upscale_factor=2)\n",
      "    (1): RDB(\n",
      "      (dense_layers): Sequential(\n",
      "        (0): make_dense(\n",
      "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): make_dense(\n",
      "          (conv): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): make_dense(\n",
      "          (conv): Conv2d(80, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (3): make_dense(\n",
      "          (conv): Conv2d(112, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (4): make_dense(\n",
      "          (conv): Conv2d(144, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): make_dense(\n",
      "          (conv): Conv2d(176, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (conv_1x1): Conv2d(208, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (2): Conv2d(16, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "True\n",
      "PSNR: 28.242, SSIM: 0.902, RMSE:0.096, time:0.16159, time:0.29236\n",
      "PSNR: 17.145, SSIM: 0.637, RMSE:0.382, time:0.00439, time:0.30690\n",
      "PSNR: 17.024, SSIM: 0.557, RMSE:0.446, time:0.00418, time:0.29239\n",
      "PSNR: 16.067, SSIM: 0.618, RMSE:0.432, time:0.00413, time:0.27758\n",
      "PSNR: 24.258, SSIM: 0.910, RMSE:0.222, time:0.00408, time:0.28771\n",
      "PSNR: 23.092, SSIM: 0.732, RMSE:0.341, time:0.00411, time:0.29332\n",
      "PSNR: 22.919, SSIM: 0.576, RMSE:0.186, time:0.00406, time:0.28721\n",
      "PSNR: 25.135, SSIM: 0.742, RMSE:0.346, time:0.00424, time:0.30007\n",
      "PSNR: 24.107, SSIM: 0.725, RMSE:0.387, time:0.00406, time:0.29451\n",
      "PSNR: 20.984, SSIM: 0.539, RMSE:0.407, time:0.00423, time:0.28731\n",
      "PSNR: 22.741, SSIM: 0.753, RMSE:0.260, time:0.00415, time:0.28795\n",
      "PSNR: 24.076, SSIM: 0.479, RMSE:0.333, time:0.00412, time:0.28600\n",
      "PSNR: 29.414, SSIM: 0.828, RMSE:0.100, time:0.00409, time:0.29881\n",
      "PSNR: 24.632, SSIM: 0.757, RMSE:0.278, time:0.00428, time:0.28738\n",
      "PSNR: 25.825, SSIM: 0.781, RMSE:0.362, time:0.00420, time:0.29403\n",
      "PSNR: 20.709, SSIM: 0.687, RMSE:0.822, time:0.00425, time:0.28482\n",
      "PSNR: 23.830, SSIM: 0.582, RMSE:0.328, time:0.00412, time:0.28757\n",
      "PSNR: 28.896, SSIM: 0.913, RMSE:0.230, time:0.00439, time:0.29100\n",
      "PSNR: 16.738, SSIM: 0.666, RMSE:0.415, time:0.00407, time:0.28200\n",
      "PSNR: 21.845, SSIM: 0.831, RMSE:0.184, time:0.00404, time:0.29349\n",
      "PSNR: 21.015, SSIM: 0.638, RMSE:0.362, time:0.00413, time:0.28891\n",
      "PSNR: 21.187, SSIM: 0.768, RMSE:0.330, time:0.00421, time:0.28541\n",
      "PSNR: 20.331, SSIM: 0.766, RMSE:0.448, time:0.00531, time:0.28657\n",
      "PSNR: 19.523, SSIM: 0.668, RMSE:0.457, time:0.00411, time:0.29449\n",
      "PSNR: 25.902, SSIM: 0.588, RMSE:0.179, time:0.00419, time:0.29254\n",
      "PSNR: 21.759, SSIM: 0.645, RMSE:0.373, time:0.00412, time:0.30165\n",
      "PSNR: 22.837, SSIM: 0.528, RMSE:0.436, time:0.00409, time:0.28919\n",
      "PSNR: 25.446, SSIM: 0.691, RMSE:0.130, time:0.00405, time:0.28604\n",
      "PSNR: 23.140, SSIM: 0.727, RMSE:0.339, time:0.00415, time:0.28829\n",
      "PSNR: 26.829, SSIM: 0.578, RMSE:0.139, time:0.00416, time:0.28235\n",
      "PSNR: 27.882, SSIM: 0.945, RMSE:0.087, time:0.00408, time:0.29059\n",
      "PSNR: 28.058, SSIM: 0.849, RMSE:0.239, time:0.00414, time:0.29060\n",
      "PSNR: 18.248, SSIM: 0.673, RMSE:0.393, time:0.00410, time:0.27924\n",
      "PSNR: 17.423, SSIM: 0.630, RMSE:0.470, time:0.00430, time:0.29003\n",
      "PSNR: 26.753, SSIM: 0.623, RMSE:0.167, time:0.00465, time:0.28338\n",
      "PSNR: 28.158, SSIM: 0.863, RMSE:0.115, time:0.00412, time:0.29655\n",
      "PSNR: 27.193, SSIM: 0.833, RMSE:0.254, time:0.00418, time:0.28647\n",
      "PSNR: 22.320, SSIM: 0.773, RMSE:0.365, time:0.00411, time:0.28609\n",
      "PSNR: 18.945, SSIM: 0.734, RMSE:0.412, time:0.00411, time:0.28930\n",
      "PSNR: 18.472, SSIM: 0.362, RMSE:0.352, time:0.00418, time:0.28616\n",
      "PSNR: 24.533, SSIM: 0.572, RMSE:0.288, time:0.00409, time:0.29567\n",
      "PSNR: 26.170, SSIM: 0.470, RMSE:0.244, time:0.00417, time:0.28273\n",
      "PSNR: 20.557, SSIM: 0.771, RMSE:0.314, time:0.00415, time:0.28385\n",
      "PSNR: 24.436, SSIM: 0.697, RMSE:0.259, time:0.00400, time:0.28533\n",
      "PSNR: 29.896, SSIM: 0.833, RMSE:0.250, time:0.00408, time:0.29097\n",
      "PSNR: 20.547, SSIM: 0.782, RMSE:0.206, time:0.00421, time:0.29259\n",
      "PSNR: 22.781, SSIM: 0.742, RMSE:0.518, time:0.00531, time:0.29412\n",
      "PSNR: 21.094, SSIM: 0.706, RMSE:0.179, time:0.00423, time:0.26872\n",
      "PSNR: 28.058, SSIM: 0.912, RMSE:0.168, time:0.00400, time:0.26690\n",
      "PSNR: 26.504, SSIM: 0.790, RMSE:0.240, time:0.00405, time:0.27772\n"
     ]
    }
   ],
   "source": [
    "gan_model = common_functions(opt)\n",
    "\n",
    "# We used MATLABs PSNR/SSIM to for getting the metrics. Although same as the ones computed by python below, we found MATLAB more \"trustworthy\"\n",
    "for iteration, img in enumerate(dataloader_train):\n",
    "    gt = img[0]\n",
    "    r_low = img[1]\n",
    "    g1_low = img[2]\n",
    "    g2_low = img[3]\n",
    "    b_low = img[4]\n",
    "    for_amplifier = img[5]\n",
    "\n",
    "    for faster in range(1):\n",
    "\n",
    "        gan_model.optimize_parameters(r_low[faster],g1_low[faster],g2_low[faster],b_low[faster],gt[faster],for_amplifier[faster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
